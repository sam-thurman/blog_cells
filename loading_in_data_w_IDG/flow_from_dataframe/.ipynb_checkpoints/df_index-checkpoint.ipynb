{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/cifar-10/'\n",
    "train_path = data_path + 'trainLabels.csv'\n",
    "\n",
    "# dfs contain filenames under \"id\" \n",
    "# we need to indicate we want our to load this in as string data\n",
    "train_df = pd.read_csv(train_path, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat           5000\n",
       "deer          5000\n",
       "airplane      5000\n",
       "horse         5000\n",
       "dog           5000\n",
       "bird          5000\n",
       "frog          5000\n",
       "ship          5000\n",
       "automobile    5000\n",
       "truck         5000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ext(filename):\n",
    "    '''\n",
    "    appends 'png' file extension to a filename (str)\n",
    "    '''\n",
    "    return filename+'.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['id'] = train_df['id'].apply(append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.png</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.png</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.png</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.png</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.png</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       label\n",
       "0  1.png        frog\n",
       "1  2.png       truck\n",
       "2  3.png       truck\n",
       "3  4.png        deer\n",
       "4  5.png  automobile"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 validated image filenames belonging to 10 classes.\n",
      "Found 10000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255.,validation_split=0.2)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                            directory=(data_path+\"train/\"),\n",
    "                                            x_col=\"id\",\n",
    "                                            y_col=\"label\",\n",
    "                                            subset=\"training\",\n",
    "                                            batch_size=32,\n",
    "                                            seed=42,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=(32,32))\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                            directory=(data_path+\"train/\"),\n",
    "                                            x_col=\"id\",\n",
    "                                            y_col=\"label\",\n",
    "                                            subset=\"validation\",\n",
    "                                            batch_size=32,\n",
    "                                            seed=42,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizers.RMSprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-f2c8445c0e23>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 115s 92ms/step - loss: 1.8723 - accuracy: 0.3138 - val_loss: 1.5717 - val_accuracy: 0.4324\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 146s 117ms/step - loss: 1.5323 - accuracy: 0.4409 - val_loss: 1.3693 - val_accuracy: 0.5066\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 139s 111ms/step - loss: 1.4042 - accuracy: 0.4944 - val_loss: 1.3726 - val_accuracy: 0.5133\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 144s 115ms/step - loss: 1.3125 - accuracy: 0.5324 - val_loss: 1.1718 - val_accuracy: 0.5812\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 154s 123ms/step - loss: 1.2363 - accuracy: 0.5642 - val_loss: 1.1291 - val_accuracy: 0.6026\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 168s 135ms/step - loss: 1.1725 - accuracy: 0.5846 - val_loss: 1.0645 - val_accuracy: 0.6234\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 149s 119ms/step - loss: 1.1209 - accuracy: 0.6068 - val_loss: 1.0395 - val_accuracy: 0.6332\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 148s 118ms/step - loss: 1.0714 - accuracy: 0.6239 - val_loss: 0.9756 - val_accuracy: 0.6566\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 152s 122ms/step - loss: 1.0351 - accuracy: 0.6363 - val_loss: 0.9532 - val_accuracy: 0.6635\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 174s 139ms/step - loss: 0.9990 - accuracy: 0.6497 - val_loss: 0.9396 - val_accuracy: 0.6688\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 183s 147ms/step - loss: 0.9659 - accuracy: 0.6632 - val_loss: 0.9080 - val_accuracy: 0.6805\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 183s 146ms/step - loss: 0.9415 - accuracy: 0.6705 - val_loss: 0.8786 - val_accuracy: 0.6903\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 147s 118ms/step - loss: 0.9142 - accuracy: 0.6810 - val_loss: 0.8699 - val_accuracy: 0.6961\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 138s 110ms/step - loss: 0.8928 - accuracy: 0.6898 - val_loss: 0.8573 - val_accuracy: 0.6953\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 139s 111ms/step - loss: 0.8735 - accuracy: 0.6944 - val_loss: 0.9004 - val_accuracy: 0.6840\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 145s 116ms/step - loss: 0.8533 - accuracy: 0.7033 - val_loss: 0.8209 - val_accuracy: 0.7115\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 137s 110ms/step - loss: 0.8371 - accuracy: 0.7087 - val_loss: 0.8168 - val_accuracy: 0.7091\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 136s 109ms/step - loss: 0.8200 - accuracy: 0.7164 - val_loss: 0.7939 - val_accuracy: 0.7224\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 139s 111ms/step - loss: 0.8069 - accuracy: 0.7196 - val_loss: 0.8003 - val_accuracy: 0.7218\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 135s 108ms/step - loss: 0.7934 - accuracy: 0.7259 - val_loss: 0.7662 - val_accuracy: 0.7324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f955f7e3e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
